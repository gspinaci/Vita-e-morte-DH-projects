{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gspinaci/Vita-e-morte-DH-projects/blob/main/giorgia_crawlerDHprojects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# URL to the spreadsheet file (e.g., Google Sheets in .xlsx format)\n",
        "url = \"https://docs.google.com/spreadsheets/d/1G3WiRMoopP8Y2FlVJfwCRqZVLilw-aMQRBxF_SoMF20/edit?gid=647909856#gid=647909856\"\n",
        "\n",
        "# Extract the spreadsheet ID from the URL\n",
        "spreadsheet_id = url.split(\"/d/\")[1].split(\"/\")[0]\n",
        "\n",
        "# Construct the download URL for Google Sheets\n",
        "download_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=xlsx\"\n",
        "\n",
        "# Load the spreadsheet using the download URL and specifying the engine\n",
        "df = pd.read_excel(download_url, sheet_name=\"Centri DH\", engine=\"openpyxl\")\n",
        "\n",
        "# Save as CSV\n",
        "df.to_csv(\"output.csv\", index=False)"
      ],
      "metadata": {
        "id": "c7NPLAnWPtxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "def create_dh_projects_scraper():\n",
        "    def is_valid_url(url):\n",
        "        \"\"\"Check if the URL is valid, adding schema if missing.\"\"\"\n",
        "        if not url:\n",
        "            return None\n",
        "        url = url.strip()\n",
        "        if not url.startswith(('http://', 'https://')):\n",
        "            url = 'https://' + url\n",
        "\n",
        "        try:\n",
        "            result = urlparse(url)\n",
        "            return url if all([result.scheme, result.netloc]) else None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def get_page_content(url):\n",
        "        \"\"\"Fetch and parse webpage content with error handling.\"\"\"\n",
        "        try:\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "            response = requests.get(url, headers=headers, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            return BeautifulSoup(response.text, 'html.parser')\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {url}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def find_project_links(soup, base_url):\n",
        "        \"\"\"Find project-related links on the page, including those in modals.\"\"\"\n",
        "        keywords = [\n",
        "            'project', 'progetti',\n",
        "            'digital humanities', 'umanistica digitale',\n",
        "            'digital', 'digitale',\n",
        "            'research', 'ricerca',\n",
        "            'laboratorio', 'laboratory',\n",
        "            'archivio', 'archive'\n",
        "        ]\n",
        "\n",
        "        exclude_domains = [\n",
        "            'facebook.com', 'twitter.com', 'linkedin.com', 'instagram.com',\n",
        "            'youtube.com', 'blogspot.com', 'wordpress.com', 'tumblr.com'\n",
        "        ]\n",
        "\n",
        "        projects = []\n",
        "        if soup:\n",
        "            # Find all potential modal containers\n",
        "            modal_elements = soup.find_all([\n",
        "                'div',  # Common modal container\n",
        "                'section',  # Sometimes used for modals\n",
        "                'aside'  # Off-canvas modals\n",
        "            ], class_=lambda x: x and any(modal_term in x.lower()\n",
        "                for modal_term in ['modal', 'popup', 'dialog', 'overlay', 'lightbox']))\n",
        "\n",
        "            # Combine regular page content and modal content\n",
        "            search_areas = [soup] + modal_elements\n",
        "\n",
        "            for area in search_areas:\n",
        "                links = area.find_all('a', href=True)\n",
        "                for link in links:\n",
        "                    href = link.get('href', '')\n",
        "                    text = link.text.lower().strip()\n",
        "\n",
        "                    # Skip empty, javascript, email, or phone links\n",
        "                    if not href or href.startswith(('javascript:', '#', 'mailto:', 'tel:')):\n",
        "                        continue\n",
        "\n",
        "                    # Make URL absolute\n",
        "                    href = urljoin(base_url, href)\n",
        "\n",
        "                    # Check if the URL should be excluded\n",
        "                    if any(domain in href for domain in exclude_domains):\n",
        "                        continue\n",
        "\n",
        "                    # Check if any keyword is in the link text or URL\n",
        "                    if any(keyword in text or keyword in href.lower() for keyword in keywords):\n",
        "                        # Check for hidden elements\n",
        "                        is_hidden = any(parent.get('style', '').lower().find('display: none') != -1\n",
        "                                      or parent.get('style', '').lower().find('visibility: hidden') != -1\n",
        "                                      for parent in link.parents)\n",
        "\n",
        "                        if not is_hidden and not any(p['link'] == href for p in projects):\n",
        "                            projects.append({\n",
        "                                'link': href,\n",
        "                                'name': text or href,\n",
        "                            })\n",
        "\n",
        "        return projects\n",
        "\n",
        "    def process_institution(row):\n",
        "        \"\"\"Process a single institution's URLs.\"\"\"\n",
        "        projects_list = []\n",
        "        if pd.notna(row['URL']):\n",
        "            # Split URLs by semicolon and handle potential whitespace\n",
        "            urls = [url.strip() for url in str(row['URL']).split(';')]\n",
        "\n",
        "            # Check if this is one of the special institutions\n",
        "            special_institutions = ['Torino', 'Catania', 'Tatti', 'Hertziana']\n",
        "            is_special = any(inst in str(row['Nome']) for inst in special_institutions)\n",
        "\n",
        "            # For special institutions, just add the URLs as project links\n",
        "            if is_special:\n",
        "                for url in urls:\n",
        "                    valid_url = is_valid_url(url)\n",
        "                    if valid_url:\n",
        "                        projects_list.append({\n",
        "                            'categoria': row['Categoria'],\n",
        "                            'institution': row['Nome'],\n",
        "                            'location': row['Luogo'],\n",
        "                            'institution_url': valid_url,\n",
        "                            'project_name': f\"Project at {row['Nome']}\",\n",
        "                            'project_link': valid_url\n",
        "                        })\n",
        "            else:\n",
        "                # Normal processing for other institutions\n",
        "                for url in urls:\n",
        "                    valid_url = is_valid_url(url)\n",
        "                    if valid_url:\n",
        "                        print(f\"  Processing URL: {valid_url}\")\n",
        "                        soup = get_page_content(valid_url)\n",
        "                        if soup:\n",
        "                            projects = find_project_links(soup, valid_url)\n",
        "\n",
        "                            for project in projects:\n",
        "                                projects_list.append({\n",
        "                                    'categoria': row['Categoria'],\n",
        "                                    'institution': row['Nome'],\n",
        "                                    'location': row['Luogo'],\n",
        "                                    'institution_url': valid_url,\n",
        "                                    'project_name': project['name'],\n",
        "                                    'project_link': project['link']\n",
        "                                })\n",
        "\n",
        "        return projects_list\n",
        "\n",
        "    def process_dh_centers(csv_path):\n",
        "        \"\"\"Main function to process the CSV file and extract project links.\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path, encoding='utf-8')\n",
        "\n",
        "            # Check if required columns are present\n",
        "            required_columns = ['Categoria', 'Nome', 'Luogo', 'URL']\n",
        "            if not all(col in df.columns for col in required_columns):\n",
        "                raise ValueError(f\"CSV must contain columns: {', '.join(required_columns)}\")\n",
        "\n",
        "            # Process all institutions, including special ones\n",
        "            all_projects = []\n",
        "            for idx, row in df.iterrows():\n",
        "                print(f\"Processing {row['Nome']}...\")\n",
        "                projects = process_institution(row)\n",
        "                all_projects.extend(projects)\n",
        "\n",
        "            results_df = pd.DataFrame(all_projects)\n",
        "\n",
        "            # Remove duplicates\n",
        "            results_df = results_df.drop_duplicates(subset=['institution', 'project_link'])\n",
        "\n",
        "            return results_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing CSV: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    return process_dh_centers\n",
        "\n",
        "# Usage example:\n",
        "if __name__ == \"__main__\":\n",
        "    scraper = create_dh_projects_scraper()\n",
        "    results = scraper('output.csv')\n",
        "\n",
        "    # Save results to CSV\n",
        "    if not results.empty:\n",
        "        results.to_csv('dh_projects_results.csv', index=False, encoding='utf-8')\n",
        "        print(f\"Found {len(results)} projects across {results['institution'].nunique()} institutions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CPuusYWMGzf",
        "outputId": "875dbedd-2de0-42b2-f7f1-eb6dfe60bea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Digital Humanities Advanced Research Centre (DH.ARC) - Unibo...\n",
            "  Processing URL: https://centri.unibo.it/dharc/en/research/projects-at-dh-arc\n",
            "Processing Venice Centre for Digital and Public Humanities (VeDPH)...\n",
            "  Processing URL: https://www.unive.it/pag/47701/\n",
            "  Processing URL: https://www.unive.it/pag/47702/\n",
            "  Processing URL: https://www.unive.it/pag/47703/\n",
            "  Processing URL: https://www.unive.it/pag/47704/\n",
            "Processing Digital Culture Laboratory - Pisa...\n",
            "  Processing URL: https://www.labcd.unipi.it/progetti/\n",
            "Processing DigiLab – Interdepartmental Center for research and services - la sapienza...\n",
            "  Processing URL: https://digilab.uniroma1.it/ricerca/progetti-corso\n",
            "Processing Interdepartmental center FiTMU – DH Section - unisalerno...\n",
            "Processing Laboratory Vast-Lab - Prato ...\n",
            "  Processing URL: https://vast-lab.org/progetti/\n",
            "Processing Centro interdipartimentale di ricerca in Digital Humanities - Università del Salento...\n",
            "Processing CRR-MM - unibo...\n",
            "  Processing URL: https://sba.unibo.it/it/almadl/collezioni/portfolio-crrmm\n",
            "Processing Centro Interdipartimentale di Ricerca \"Digital Scholarship for the Humanities\" DISH Università di Torino...\n",
            "Processing Centro Interdisciplinare di Ricerche per la Computerizzazione dei Segni dell'Espressione Università Cattolica di Milano...\n",
            "  Processing URL: https://centridiricerca.unicatt.it/circse/it/progetti.html\n",
            "Processing Centro di Informatica Umanistica - Università degli Studi di Catania...\n",
            "Processing Laboratorio CRILeT \"Giuseppe Gigliozzi\" - Sapienza Università di Roma...\n",
            "Processing Laboratorio di Informatica Umanistica e Cultura Digitale - Università di Parma...\n",
            "  Processing URL: https://dhlab.unipr.it/?page_id=178\n",
            "Processing Digital Arena for Inclusive Humanities - Università di Verona...\n",
            "Processing LUDICA: Laboratorio di Umanistica Digitale Università di Cagliari...\n",
            "  Processing URL: https://www.unica.it/unica/it/news_avvisi_s1.page?contentId=AVS162074\n",
            "Processing nan...\n",
            "Processing Digital humanities lab - kunsthistoriches florenz...\n",
            "  Processing URL: https://www.khi.fi.it/en/forschung/digital-humanities/index.php\n",
            "Processing Digitatti - Villa I tatti Florence...\n",
            "  Processing URL: https://florentinedrawings.itatti.harvard.edu/resource/Start\n",
            "  Processing URL: https://cria.itatti.harvard.edu/\n",
            "  Processing URL: https://pharosartresearch.org/\n",
            "  Processing URL: https://yashiro.itatti.harvard.edu/\n",
            "  Processing URL: https://bellegreene.itatti.harvard.edu/resource/rsp:Letters\n",
            "Processing Digital humanties lab - Bibliotheca hertziana (rome)...\n",
            "  Processing URL: https://maps.biblhertz.it/gis/precat\n",
            "  Processing URL: https://biblhertz.github.io/atlas/\n",
            "  Processing URL: https://db.biblhertz.it/siena/siena.xql\n",
            "  Processing URL: https://wissensgeschichte.biblhertz.it/3d-bridge-html/index3D.html\n",
            "  Processing URL: https://dlib.biblhertz.it/\n",
            "  Processing URL: https://rara.biblhertz.it/\n",
            "  Processing URL: https://foto.biblhertz.it/\n",
            "  Processing URL: https://zuccaro.biblhertz.it/\n",
            "  Processing URL: https://dlib.biblhertz.it/urbs/#14.29/41.89547/12.46792/17.7\n",
            "  Processing URL: https://dlib.biblhertz.it/spatial/#15.96/41.895619/12.477807/20\n",
            "  Processing URL: https://dlib.biblhertz.it/guide/\n",
            "  Processing URL: https://db.biblhertz.it/noack/noack.xml\n",
            "  Processing URL: https://cipro.biblhertz.it/\n",
            "  Processing URL: https://fm.biblhertz.it/fmi/xsl/home.xsl?-token.proj=li\n",
            "  Processing URL: https://db.biblhertz.it/abruzzo/index.xml\n",
            "  Processing URL: https://wissensgeschichte.biblhertz.it/Glossario\n",
            "  Processing URL: https://maps.biblhertz.it/\n",
            "  Processing URL: https://staccioli.biblhertz.it/resource/Default:Start\n",
            "  Processing URL: https://echaurren.biblhertz.it/PE.html\n",
            "  Processing URL: https://dlib.biblhertz.it/places#17.35/41.896072/12.482376\n",
            "  Processing URL: https://data.biblhertz.it/\n",
            "  Processing URL: https://confluenze.dev/#16.5/42.348011/13.397988/-69/26\n",
            "  Processing URL: https://dlib.biblhertz.it/perspectiva/\n",
            "  Processing URL: https://editions.humanitiesconnect.pub/exist/apps/hwgw/index.html\n",
            "Processing DH Research Group – ICT Center – Fondazione Bruno Kessler ...\n",
            "  Processing URL: https://dh.fbk.eu/category/projects/\n",
            "Processing nan...\n",
            "Processing ILIESI Institute - cnr roma...\n",
            "  Processing URL: https://www.iliesi.cnr.it/attivita.php?tp=a_d\n",
            "Processing Institute for Computational Linguistics «A. Zampolli» - pisa...\n",
            "  Processing URL: https://www.ilc.cnr.it/progetti-attivi/\n",
            "  Processing URL: https://www.ilc.cnr.it/progetti/\n",
            "Processing Visual Computing Lab – ISTI – CNR -...\n",
            "  Processing URL: https://www.labcd.unipi.it/en/osservatorio/visual-computing-lab-isti-cnr-2/\n",
            "Found 312 projects across 18 institutions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from urllib3.util.retry import Retry\n",
        "from requests.adapters import HTTPAdapter\n",
        "\n",
        "def create_session_with_retries():\n",
        "    \"\"\"Create a requests session with retry strategy\"\"\"\n",
        "    session = requests.Session()\n",
        "    retries = Retry(\n",
        "        total=3,\n",
        "        backoff_factor=0.5,\n",
        "        status_forcelist=[500, 502, 503, 504]\n",
        "    )\n",
        "    adapter = HTTPAdapter(max_retries=retries)\n",
        "    session.mount('http://', adapter)\n",
        "    session.mount('https://', adapter)\n",
        "    return session\n",
        "\n",
        "def check_links_status(csv_path):\n",
        "    \"\"\"Check status of project links and create a clean status report\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, encoding='utf-8')\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV file: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    # Create a session with retry strategy\n",
        "    session = create_session_with_retries()\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    # Create lists to store results\n",
        "    results = []\n",
        "\n",
        "    # Check each link\n",
        "    for index, row in df.iterrows():\n",
        "        url = row['project_link']\n",
        "        print(f\"Checking {index + 1}/{len(df)}: {url}\")\n",
        "\n",
        "        try:\n",
        "            response = session.get(url, headers=headers, timeout=10, allow_redirects=True)\n",
        "            status_code = response.status_code\n",
        "\n",
        "            # Determine website status\n",
        "            if 200 <= status_code < 300:\n",
        "                status = \"Active\"\n",
        "            elif status_code == 404:\n",
        "                status = \"Not Found\"\n",
        "            elif 300 <= status_code < 400:\n",
        "                status = f\"Redirect ({status_code})\"\n",
        "            elif 400 <= status_code < 500:\n",
        "                status = f\"Client Error ({status_code})\"\n",
        "            elif 500 <= status_code < 600:\n",
        "                status = f\"Server Error ({status_code})\"\n",
        "            else:\n",
        "                status = f\"Unknown ({status_code})\"\n",
        "\n",
        "            results.append({\n",
        "                'institution': row['institution'],\n",
        "                'project_name': row['project_name'],\n",
        "                'url': url,\n",
        "                'status_code': status_code,\n",
        "                'status': status,\n",
        "                'response': \"Success\" if 200 <= status_code < 300 else \"Failed\"\n",
        "            })\n",
        "\n",
        "        except requests.exceptions.ConnectionError:\n",
        "            results.append({\n",
        "                'institution': row['institution'],\n",
        "                'project_name': row['project_name'],\n",
        "                'url': url,\n",
        "                'status_code': None,\n",
        "                'status': \"Connection Error\",\n",
        "                'response': \"Failed\"\n",
        "            })\n",
        "        except requests.exceptions.Timeout:\n",
        "            results.append({\n",
        "                'institution': row['institution'],\n",
        "                'project_name': row['project_name'],\n",
        "                'url': url,\n",
        "                'status_code': None,\n",
        "                'status': \"Timeout\",\n",
        "                'response': \"Failed\"\n",
        "            })\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            results.append({\n",
        "                'institution': row['institution'],\n",
        "                'project_name': row['project_name'],\n",
        "                'url': url,\n",
        "                'status_code': None,\n",
        "                'status': f\"Error: {str(e)[:100]}...\",\n",
        "                'response': \"Failed\"\n",
        "            })\n",
        "\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    # Create DataFrame from results\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Calculate statistics\n",
        "    total_links = len(results_df)\n",
        "    active_links = len(results_df[results_df['response'] == \"Success\"])\n",
        "    failed_links = total_links - active_links\n",
        "\n",
        "    print(\"\\nSummary:\")\n",
        "    print(f\"Total links checked: {total_links}\")\n",
        "    print(f\"Active links: {active_links}\")\n",
        "    print(f\"Failed links: {failed_links}\")\n",
        "\n",
        "    # Save to CSV\n",
        "    results_df.to_csv('website_status_report.csv', index=False, encoding='utf-8')\n",
        "    print(\"\\nDetailed results saved to: website_status_report.csv\")\n",
        "\n",
        "    return results_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results_df = check_links_status('dh_projects_results.csv')\n",
        "\n",
        "    if results_df is not None:\n",
        "        # Display a sample of the results\n",
        "        print(\"\\nSample of results:\")\n",
        "        print(results_df[['institution', 'project_name', 'url', 'status', 'response']].head())\n",
        "\n",
        "        # Display breakdown of different status types\n",
        "        print(\"\\nStatus breakdown:\")\n",
        "        print(results_df['status'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMXL02YEMSax",
        "outputId": "e3919e74-d266-4960-d99b-9015ea76a062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 1/312: https://centri.unibo.it/dharc/en\n",
            "Checking 2/312: https://centri.unibo.it/dharc/en/research\n",
            "Checking 3/312: https://centri.unibo.it/dharc/en/research/topics\n",
            "Checking 4/312: https://centri.unibo.it/dharc/en/research/projects-at-dh-arc\n",
            "Checking 5/312: https://centri.unibo.it/dharc/en/research/partner\n",
            "Checking 6/312: https://centri.unibo.it/dharc/en/research/visiting-fellow\n",
            "Checking 7/312: http://www.iccd.beniculturali.it/it/progetti/4597/arco-architettura-della-conoscenza-ontologie-per-la-descrizione-del-patrimonio-culturale\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7d734256bdc0>, 'Connection to www.iccd.beniculturali.it timed out. (connect timeout=10)')': /it/progetti/4597/arco-architettura-della-conoscenza-ontologie-per-la-descrizione-del-patrimonio-culturale\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7d734256a8c0>, 'Connection to www.iccd.beniculturali.it timed out. (connect timeout=10)')': /it/progetti/4597/arco-architettura-della-conoscenza-ontologie-per-la-descrizione-del-patrimonio-culturale\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7d734256b610>, 'Connection to www.iccd.beniculturali.it timed out. (connect timeout=10)')': /it/progetti/4597/arco-architettura-della-conoscenza-ontologie-per-la-descrizione-del-patrimonio-culturale\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342568ca0>: Failed to establish a new connection: [Errno 111] Connection refused')': /\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 8/312: http://artchives.fondazionezeri.unibo.it/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342a534c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342a52ef0>: Failed to establish a new connection: [Errno 111] Connection refused')': /\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 9/312: https://polifonia-project.github.io/clef/\n",
            "Checking 10/312: https://github.com/polifonia-project/registry_app\n",
            "Checking 11/312: https://projects.dharc.unibo.it/dhdkey/\n",
            "Checking 12/312: https://dl.ficlit.unibo.it\n",
            "Checking 13/312: https://aldomorodigitale.unibo.it/\n",
            "Checking 14/312: http://www.mario-project.eu/portal/\n",
            "Checking 15/312: https://www.iks-project.eu/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.iks-project.eu'. (_ssl.c:1007)\"))': /\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.iks-project.eu'. (_ssl.c:1007)\"))': /\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.iks-project.eu'. (_ssl.c:1007)\"))': /\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 16/312: https://icdp-digital-library.github.io/KNOT/\n",
            "Checking 17/312: https://projects.dharc.unibo.it/knot/\n",
            "Checking 18/312: https://projects.dharc.unibo.it/leggomanzoni/\n",
            "Checking 19/312: https://projects.dharc.unibo.it/lift/\n",
            "Checking 20/312: http://projects.dharc.unibo.it/mauth/search\n",
            "Checking 21/312: https://projects.dharc.unibo.it/melody/\n",
            "Checking 22/312: https://projects.dharc.unibo.it/odi/\n",
            "Checking 23/312: http://projects.dharc.unibo.it/philoeditor/\n",
            "Checking 24/312: https://raguproject.github.io/\n",
            "Checking 25/312: http://projects.dharc.unibo.it/bufalini-notebook/\n",
            "Checking 26/312: http://vespasianodabisticciletters.unibo.it/\n",
            "Checking 27/312: http://projects.dharc.unibo.it/vespasiano/\n",
            "Checking 28/312: https://shivadharmaproject.com/the-sivadhama-infrastructure-modeling-a-web-application-for-managing-scholarly-data/\n",
            "Checking 29/312: https://cordis.europa.eu/project/id/870811\n",
            "Checking 30/312: http://projects.dharc.unibo.it/uhdw/\n",
            "Checking 31/312: https://www.unive.it/pag/40315/\n",
            "Checking 32/312: https://pric.unive.it/projects/liber/home\n",
            "Checking 33/312: http://www.mqdq.it\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7d73425cb970>: Failed to resolve 'it' ([Errno -5] No address associated with hostname)\")': /264/laboratorio-di-epigrafia-greca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 34/312: http://it/264/laboratorio-di-epigrafia-greca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7d7342bc79d0>: Failed to resolve 'it' ([Errno -5] No address associated with hostname)\")': /264/laboratorio-di-epigrafia-greca\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NameResolutionError(\"<urllib3.connection.HTTPConnection object at 0x7d73429465f0>: Failed to resolve 'it' ([Errno -5] No address associated with hostname)\")': /264/laboratorio-di-epigrafia-greca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 35/312: https://www.digitalepigraphy.org/\n",
            "Checking 36/312: https://miur.gov.it/\n",
            "Checking 37/312: https://www.unive.it/pag/47701/?id=33924\n",
            "Checking 38/312: https://pric.unive.it/progetti/archivio-fonti-orali/home\n",
            "Checking 39/312: https://www.medici.org/the-falconieri-project/\n",
            "Checking 40/312: https://www.odycceus.eu/project/\n",
            "Checking 41/312: https://www.unive.it/pag/47702/?id=33924\n",
            "Checking 42/312: https://www.unive.it/pag/47703/?id=33924\n",
            "Checking 43/312: https://www.unive.it/pag/47704/?id=33924\n",
            "Checking 44/312: https://www.labcd.unipi.it/laboratorio/\n",
            "Checking 45/312: https://www.labcd.unipi.it/laboratorio/filosofia/\n",
            "Checking 46/312: https://www.labcd.unipi.it/laboratorio/missione/\n",
            "Checking 47/312: https://www.labcd.unipi.it/laboratorio/persone/\n",
            "Checking 48/312: https://www.labcd.unipi.it/laboratorio/dipartimenti/\n",
            "Checking 49/312: https://www.labcd.unipi.it/laboratorio/storia-2/\n",
            "Checking 50/312: https://www.labcd.unipi.it/laboratorio/regolamento/\n",
            "Checking 51/312: https://www.labcd.unipi.it/laboratorio/partner/\n",
            "Checking 52/312: https://www.labcd.unipi.it/progetti\n",
            "Checking 53/312: http://www.labcd.unipi.it/tutti-i-progetti\n",
            "Checking 54/312: https://www.labcd.unipi.it/progetti/i-confini-della-lunigiana/\n",
            "Checking 55/312: https://www.labcd.unipi.it/progetti/teatro-in-fuga-digitale/\n",
            "Checking 56/312: https://www.labcd.unipi.it/progetti/teddy-4-kids/\n",
            "Checking 57/312: https://www.labcd.unipi.it/progetti/i-quaderni-del-laboratorio-di-cultura-digitale/\n",
            "Checking 58/312: https://www.labcd.unipi.it/progetti/fibonacci-1202-2021/\n",
            "Checking 59/312: https://www.labcd.unipi.it/progetti/i-registri-parrocchiali-di-monterosso-al-mare/\n",
            "Checking 60/312: https://www.labcd.unipi.it/progetti/7075/\n",
            "Checking 61/312: https://www.labcd.unipi.it/progetti/odonomastica-femminile/\n",
            "Checking 62/312: https://www.labcd.unipi.it/progetti/page/2/\n",
            "Checking 63/312: https://www.labcd.unipi.it/progetti/page/7/\n",
            "Checking 64/312: https://www.labcd.unipi.it/progetti-europei\n",
            "Checking 65/312: https://www.labcd.unipi.it/progetti/categoria/progettazione-web/\n",
            "Checking 66/312: https://www.labcd.unipi.it/progetti/categoria/multimedia/\n",
            "Checking 67/312: https://www.labcd.unipi.it/progetti/categoria/web-grafica/\n",
            "Checking 68/312: https://www.labcd.unipi.it/progetti/categoria/public-history/\n",
            "Checking 69/312: https://www.labcd.unipi.it/progetti/categoria/wordpress/\n",
            "Checking 70/312: https://www.labcd.unipi.it/progetti/categoria/storia-digitale/\n",
            "Checking 71/312: https://www.labcd.unipi.it/progetti/categoria/editoria-elettronica/\n",
            "Checking 72/312: https://www.labcd.unipi.it/progetti/categoria/archivi/\n",
            "Checking 73/312: https://www.labcd.unipi.it/progetti/categoria/bibliografia-on-line/\n",
            "Checking 74/312: https://www.labcd.unipi.it/progetti/categoria/storia-dellarte/\n",
            "Checking 75/312: https://www.labcd.unipi.it/progetti/categoria/elearning/\n",
            "Checking 76/312: https://www.labcd.unipi.it/progetti/categoria/grafica-3d/\n",
            "Checking 77/312: https://www.labcd.unipi.it/progetti/categoria/transmedia-storytelling/\n",
            "Checking 78/312: https://www.labcd.unipi.it/progetti/categoria/webgis/\n",
            "Checking 79/312: https://www.labcd.unipi.it/progetti/categoria/linguistica-computazionale/\n",
            "Checking 80/312: https://www.labcd.unipi.it/progetti/categoria/teatro/\n",
            "Checking 81/312: https://www.labcd.unipi.it/progetti/categoria/infanzia/\n",
            "Checking 82/312: https://www.labcd.unipi.it/progetti/categoria/intelligenza-artificiale/\n",
            "Checking 83/312: https://www.labcd.unipi.it/progetti/categoria/medicina/\n",
            "Checking 84/312: https://www.labcd.unipi.it/progetti/categoria/app/\n",
            "Checking 85/312: https://www.labcd.unipi.it/progetti/categoria/podcast/\n",
            "Checking 86/312: https://www.labcd.unipi.it/progetti/categoria/grafica-tradizionale/\n",
            "Checking 87/312: https://digilab.uniroma1.it/ricerca/progetti-corso\n",
            "Checking 88/312: https://digilab.uniroma1.it/en/research/current-projects\n",
            "Checking 89/312: https://digilab.uniroma1.it/\n",
            "Checking 90/312: https://digilab.uniroma1.it/centro/ricercatori-0\n",
            "Checking 91/312: https://digilab.uniroma1.it/ricerca\n",
            "Checking 92/312: https://digilab.uniroma1.it/ricerca/progetti-conclusi\n",
            "Checking 93/312: https://digilab.uniroma1.it/attivit/patrimoni-culturali-e-digital-curation\n",
            "Checking 94/312: https://digilab.uniroma1.it/ricerca/progetti-corso/osservatorio-ospac\n",
            "Checking 95/312: https://digilab.uniroma1.it/ricerca/progetti-corso/hermes\n",
            "Checking 96/312: https://digilab.uniroma1.it/ricerca/progetti-corso/artemisia\n",
            "Checking 97/312: https://digilab.uniroma1.it/ricerca/progetti-corso/attract\n",
            "Checking 98/312: https://digilab.uniroma1.it/ricerca/progetti-corso/int4ct\n",
            "Checking 99/312: https://digilab.uniroma1.it/ricerca/progetti-corso/step\n",
            "Checking 100/312: https://digilab.uniroma1.it/ricerca/progetti-corso/sanlo\n",
            "Checking 101/312: https://digilab.uniroma1.it/ricerca/progetti-corso/contamination-lab-celio\n",
            "Checking 102/312: https://digilab.uniroma1.it/ricerca/progetti-corso/picturing-lost-empire\n",
            "Checking 103/312: https://digilab.uniroma1.it/ricerca/progetti-corso/mirror-lab\n",
            "Checking 104/312: https://digilab.uniroma1.it/ricerca/progetti-corso/newtimes\n",
            "Checking 105/312: https://vast-lab.org/progetti/\n",
            "Checking 106/312: https://vast-lab.org/progetti/atrium/\n",
            "Checking 107/312: https://vast-lab.org/progetti/4-ch/\n",
            "Checking 108/312: https://vast-lab.org/progetti/ariadneplus/\n",
            "Checking 109/312: https://vast-lab.org/progetti/parthenos/\n",
            "Checking 110/312: https://vast-lab.org/progetti/ariadne/\n",
            "Checking 111/312: https://vast-lab.org/progetti/erihs/\n",
            "Checking 112/312: https://vast-lab.org/progetti/riscape/\n",
            "Checking 113/312: https://vast-lab.org/progetti/eosc/\n",
            "Checking 114/312: https://vast-lab.org/progetti/openaire/\n",
            "Checking 115/312: https://vast-lab.org/progetti/creativech/\n",
            "Checking 116/312: https://vast-lab.org/progetti/3dcoform-2/\n",
            "Checking 117/312: https://vast-lab.org/progetti/epoch/\n",
            "Checking 118/312: https://vast-lab.org/progetti/3dicons/\n",
            "Checking 119/312: https://vast-lab.org/progetti/chiron/\n",
            "Checking 120/312: https://vast-lab.org/progetti/coins/\n",
            "Checking 121/312: https://sba.unibo.it/it/chi-siamo/progetti\n",
            "Checking 122/312: https://sba.unibo.it/it/cataloghi/altri-strumenti-di-ricerca-di-ateneo\n",
            "Checking 123/312: http://www.unibo.it/it/servizi-e-opportunita/biblioteche-risorse-digitali-e-sale-studio/sale-studio\n",
            "Checking 124/312: http://vcg.isti.cnr.it/cross/\n",
            "Checking 125/312: http://pelavicino.labcd.unipi.it/\n",
            "Checking 126/312: http://vcg.isti.cnr.it/activities/visionarycross/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342568a00>: Failed to establish a new connection: [Errno 111] Connection refused')': /beta2/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 127/312: http://vbd.humnet.unipi.it/beta2/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342bc79d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /beta2/\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d73425cb9d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /beta2/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 128/312: http://iu.di.unipi.it/flos/\n",
            "Checking 129/312: http://www.labcd.unipi.it/matildedicanossa\n",
            "Checking 130/312: https://www.classici-dse.com/\n",
            "Checking 131/312: https://sourceforge.net/projects/evt-project/\n",
            "Checking 132/312: http://evt.labcd.unipi.it/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342568e50>: Failed to establish a new connection: [Errno 111] Connection refused')': /\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342945480>: Failed to establish a new connection: [Errno 111] Connection refused')': /\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d7342945120>: Failed to establish a new connection: [Errno 111] Connection refused')': /\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 133/312: https://www.openliterature.unito.it/\n",
            "Checking 134/312: https://centridiricerca.unicatt.it/circse/it.html\n",
            "Checking 135/312: https://centridiricerca.unicatt.it/circse/it/progetti.html\n",
            "Checking 136/312: https://centridiricerca.unicatt.it/circse/it/pubblicazioni.html\n",
            "Checking 137/312: https://centridiricerca.unicatt.it/circse/it/news.html\n",
            "Checking 138/312: https://centridiricerca.unicatt.it/circse/it/eventi.html\n",
            "Checking 139/312: https://centridiricerca.unicatt.it/circse/en.html\n",
            "Checking 140/312: https://centridiricerca.unicatt.it/circse/en/projects.html\n",
            "Checking 141/312: https://centridiricerca.unicatt.it/circse/it/il-centro/Il-centro.html\n",
            "Checking 142/312: https://centridiricerca.unicatt.it/circse/it/il-centro/statuto.html\n",
            "Checking 143/312: https://centridiricerca.unicatt.it/circse/it/il-centro/comitato-direttivo.html\n",
            "Checking 144/312: https://centridiricerca.unicatt.it/circse/it/il-centro/comitato-scientifico.html\n",
            "Checking 145/312: https://centridiricerca.unicatt.it/circse/it/il-centro/staff.html\n",
            "Checking 146/312: https://centridiricerca.unicatt.it/circse/it/il-centro/servizi.html\n",
            "Checking 147/312: https://centridiricerca.unicatt.it/circse/it/il-centro/contatti.html\n",
            "Checking 148/312: https://centridiricerca.unicatt.it/circse/it\n",
            "Checking 149/312: https://centridiricerca.unicatt.it/circse/it/progetti/lila.html\n",
            "Checking 150/312: https://centridiricerca.unicatt.it/circse/it/progetti/index-thomisticus-treebank.html\n",
            "Checking 151/312: https://centridiricerca.unicatt.it/circse/it/progetti/word-formation-latin.html\n",
            "Checking 152/312: https://centridiricerca.unicatt.it/circse/it/progetti/CorefLat.html\n",
            "Checking 153/312: https://centridiricerca.unicatt.it/circse/it/progetti/moLor.html\n",
            "Checking 154/312: http://www.perseus.tufts.edu/hopper/\n",
            "Checking 155/312: https://www.hf.uio.no/ifikk/english/research/projects/proiel/\n",
            "Checking 156/312: http://www.gcdh.de/en/\n",
            "Checking 157/312: https://alpion.unict.it\n",
            "Checking 158/312: http://www.artesia.unict.it/\n",
            "Checking 159/312: https://linea.unict.it\n",
            "Checking 160/312: https://poichilia.unict.it\n",
            "Checking 161/312: http://www.pirandellonazionale.it/\n",
            "Checking 162/312: http://dhlab.unipr.it/?page_id=178\n",
            "Checking 163/312: https://italianacademy.columbia.edu/content/frida\n",
            "Checking 164/312: https://www.alessandromanzoni.org\n",
            "Checking 165/312: https://nsa.unipr.it\n",
            "Checking 166/312: http://www.papirologia.unipr.it/ricerca/prin2017.html\n",
            "Checking 167/312: https://www.clarin.eu/content/archilochus-paros-elegiac-fragments-xml-archive\n",
            "Checking 168/312: http://www.papirologia.unipr.it/ricerca/tebtynis.html\n",
            "Checking 169/312: https://www.thinkbigparma.it/prima-edizione/project/cittaumentata/\n",
            "Checking 170/312: http://www.istruzione.it\n",
            "Checking 171/312: https://web.unica.it/unica/it/ateneo_s07.page\n",
            "Checking 172/312: https://web.unica.it/unica/it/laureati_s04.page\n",
            "Checking 173/312: https://web.unica.it/unica/it/ricerca.page\n",
            "Checking 174/312: https://web.unica.it/unica/it/ricerca_s08.page\n",
            "Checking 175/312: https://web.unica.it/unica/it/ricerca_s02.page\n",
            "Checking 176/312: https://web.unica.it/unica/it/ricerca_s03.page\n",
            "Checking 177/312: https://web.unica.it/unica/it/ricerca_s04.page\n",
            "Checking 178/312: https://web.unica.it/unica/it/ricerca_s05.page\n",
            "Checking 179/312: https://web.unica.it/unica/it/ricerca_s09.page\n",
            "Checking 180/312: https://web.unica.it/unica/it/ricerca_s06.page\n",
            "Checking 181/312: https://web.unica.it/unica/it/ricerca_s07.page\n",
            "Checking 182/312: https://web.unica.it/unica/it/ricerca_apdm.page\n",
            "Checking 183/312: https://web.unica.it/unica/it/utility_ricerca.page\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='web.unica.it', port=443): Read timed out. (read timeout=10)\")': /unica/it/utility_ricerca.page\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='web.unica.it', port=443): Read timed out. (read timeout=10)\")': /unica/it/utility_ricerca.page\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='web.unica.it', port=443): Read timed out. (read timeout=10)\")': /unica/it/utility_ricerca.page\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 184/312: https://web.unica.it/unica/it/ufficio_stampa_ricerca.page\n",
            "Checking 185/312: https://www.indicepa.it/ipa-portale/consultazione/domicilio-digitale/ricerca-domicili-digitali-ente/scheda-ente/22683\n",
            "Checking 186/312: https://www.khi.fi.it/en/institut/forschungsbereiche.php\n",
            "Checking 187/312: https://www.khi.fi.it/en/institut/foerderangebot.php\n",
            "Checking 188/312: https://www.khi.fi.it/en/institut/archive.php\n",
            "Checking 189/312: https://www.khi.fi.it/en/forschung/index.php\n",
            "Checking 190/312: https://www.khi.fi.it/en/forschung/senior-research-scholar-baader/index.php\n",
            "Checking 191/312: https://www.khi.fi.it/en/forschung/senior-research-scholar-gruendler/index.php\n",
            "Checking 192/312: https://www.khi.fi.it/en/forschung/4a-laboratory/index.php\n",
            "Checking 193/312: https://www.khi.fi.it/en/forschung/digital-humanities/index.php\n",
            "Checking 194/312: https://www.khi.fi.it/en/forschung/promovierende/index.php\n",
            "Checking 195/312: https://www.khi.fi.it/en/forschung/postdoktoranden/index.php\n",
            "Checking 196/312: https://www.khi.fi.it/en/forschung/wissenschaftliche-mitarbeiter/index.php\n",
            "Checking 197/312: https://www.khi.fi.it/en/forschung/kooperationsprojekte/index.php\n",
            "Checking 198/312: https://www.khi.fi.it/en/forschung/assoziierte-projekte/index.php\n",
            "Checking 199/312: https://www.khi.fi.it/en/forschung/abgeschlossene-projekte/index.php\n",
            "Checking 200/312: https://www.khi.fi.it/en/publikationen/forschungsberichte/index.php\n",
            "Checking 201/312: https://www.khi.fi.it/en/bibliothek/digitale-bibliothek.php\n",
            "Checking 202/312: https://www.khi.fi.it/en/bibliothek/projekte.php\n",
            "Checking 203/312: https://www.khi.fi.it/en/photothek/digitale-ressourcen.php\n",
            "Checking 204/312: https://www.khi.fi.it/en/photothek/projekte.php\n",
            "Checking 205/312: https://www.khi.fi.it/de/forschung/digital-humanities/index.php\n",
            "Checking 206/312: https://www.khi.fi.it/it/forschung/digital-humanities/index.php\n",
            "Checking 207/312: https://www.khi.fi.it/en/forschung/digital-humanities/dante-depicted.php\n",
            "Checking 208/312: https://www.khi.fi.it/en/forschung/digital-humanities/aby-warburgs-florence.php\n",
            "Checking 209/312: https://www.khi.fi.it/en/forschung/digital-humanities/gigapixel-images.php\n",
            "Checking 210/312: https://www.khi.fi.it/en/forschung/digital-humanities/connecting-the-khi-digital-resources.php\n",
            "Checking 211/312: https://www.khi.fi.it/en/forschung/digital-humanities/michelangelo-su-carta.php\n",
            "Checking 212/312: https://www.khi.fi.it/en/forschung/digital-humanities/digitizing-the-die-kirchen-von-siena-project.php\n",
            "Checking 213/312: https://www.khi.fi.it/en/forschung/digital-humanities/virtual-repository-of-photographers-sales-catalogues.php\n",
            "Checking 214/312: https://www.khi.fi.it/en/forschung/digital-humanities/khi-digital-humanities-microservices-environment.php\n",
            "Checking 215/312: http://photothek.khi.fi.it/?Language=en\n",
            "Checking 216/312: https://pharosartresearch.org/\n",
            "Checking 217/312: https://pharosartresearch.org/pharos/home\n",
            "Checking 218/312: http://pharosartresearch.org/#overlay=cp/support\n",
            "Checking 219/312: https://pharosartresearch.org/about\n",
            "Checking 220/312: https://pharosartresearch.org/institutions\n",
            "Checking 221/312: https://pharosartresearch.org/initiatives\n",
            "Checking 222/312: https://vision.artresearch.net/resource/start\n",
            "Checking 223/312: https://pharosartresearch.org/news\n",
            "Checking 224/312: https://pharosartresearch.org/news/report-ip-working-group-international-copyright\n",
            "Checking 225/312: https://pharosartresearch.org/news/pharos-receives-andrew-w-mellon-foundation-grant\n",
            "Checking 226/312: https://pharosartresearch.org/news/meeting-pharos-international-consortium-photo-archives-hague-rkd-october-8-2018\n",
            "Checking 227/312: http://www.getty.edu/research/\n",
            "Checking 228/312: https://pharosartresearch.org/pharos/contact\n",
            "Checking 229/312: https://pharosartresearch.org/user?destination=home%3Fadmin_panel%3D1%26login%3D1\n",
            "Checking 230/312: https://yashiro.itatti.harvard.edu/Yamanashi\n",
            "Checking 231/312: https://biblhertz.github.io/BHLabs/\n",
            "Checking 232/312: https://db.biblhertz.it/siena/project.xml\n",
            "Checking 233/312: https://wissensgeschichte.biblhertz.it/3d-bridge-html/outline.html\n",
            "Checking 234/312: https://foto.biblhertz.it/cms/Piersanti\n",
            "Checking 235/312: https://www.comicon.it/class/alla-ricerca-dellunderground-riviste-stampa-alternativa-generazioni/\n",
            "Checking 236/312: https://dlib.biblhertz.it/perspectiva/project.html#pro01\n",
            "Checking 237/312: https://dlib.biblhertz.it/perspectiva/project.html#pro02\n",
            "Checking 238/312: https://dlib.biblhertz.it/perspectiva/project.html#pro03\n",
            "Checking 239/312: https://editions.humanitiesconnect.pub/exist/apps/hwgw/project.html\n",
            "Checking 240/312: https://editions.humanitiesconnect.pub/exist/apps/hwgw/s03/index.html\n",
            "Checking 241/312: https://editions.humanitiesconnect.pub/exist/apps/hwgw/s04/index.html\n",
            "Checking 242/312: https://dh.fbk.eu/category/projects/\n",
            "Checking 243/312: https://dh.fbk.eu/research/\n",
            "Checking 244/312: https://dh.fbk.eu/2024/07/ai-code-ai-services-for-continuous-trust-in-emerging-digital-environments/\n",
            "Checking 245/312: https://dh.fbk.eu/2023/01/stand-by-me-project-fight-violence-against-women/\n",
            "Checking 246/312: https://dh.fbk.eu/2020/11/university-research-funding-patenting-and-technological-impact/\n",
            "Checking 247/312: https://dh.fbk.eu/2017/02/epistolario-national-edition-of-de-gasperis-letters-in-digital-format/\n",
            "Checking 248/312: https://dh.fbk.eu/2016/06/simpatico-h2020-project/\n",
            "Checking 249/312: https://dh.fbk.eu/2013/07/vvv-verbo-visuale-virtuale-la-piattaforma-di-ricerca-interattiva-dellarte-verbo-visuale/\n",
            "Checking 250/312: https://dh.fbk.eu/2013/06/alcide-analysis-of-language-and-content-in-a-digital-environment/\n",
            "Checking 251/312: https://dh.fbk.eu/2024/10/ircdl2025/\n",
            "Checking 252/312: https://www.iliesi.cnr.it/risorsedigitali\n",
            "Checking 253/312: https://www.iliesi.cnr.it/attivita.php?tp=a_d\n",
            "Checking 254/312: https://www.iliesi.cnr.it/iniziative/Descartes-Lab-Poster-Andrault-DEF.pdf\n",
            "Checking 255/312: https://bit.ly/descartes-laboratory\n",
            "Checking 256/312: https://www.ilc.cnr.it/en/current-projects/\n",
            "Checking 257/312: https://www.ilc.cnr.it/cenni-storici/bibliografia-di-antonio-zampolli/\n",
            "Checking 258/312: https://www.ilc.cnr.it/linee-di-ricerca/\n",
            "Checking 259/312: https://www.ilc.cnr.it/gruppi-di-ricerca-e-laboratori/\n",
            "Checking 260/312: https://www.ilc.cnr.it/infrastrutture/\n",
            "Checking 261/312: https://www.ilc.cnr.it/progetti-attivi/\n",
            "Checking 262/312: https://www.ilc.cnr.it/progetti/\n",
            "Checking 263/312: https://www.ilc.cnr.it/progetti/epica/\n",
            "Checking 264/312: https://www.ilc.cnr.it/progetti/castour/\n",
            "Checking 265/312: https://www.ilc.cnr.it/progetti/fringe-project/\n",
            "Checking 266/312: https://www.ilc.cnr.it/progetti/raise/\n",
            "Checking 267/312: https://www.ilc.cnr.it/progetti/teaming-up/\n",
            "Checking 268/312: https://www.ilc.cnr.it/progetti/atlas/\n",
            "Checking 269/312: https://www.ilc.cnr.it/progetti/skills4eosc/\n",
            "Checking 270/312: https://www.ilc.cnr.it/progetti/h2iosc/\n",
            "Checking 271/312: https://www.ilc.cnr.it/progetti/manuscripta-italica-allographica-mia/\n",
            "Checking 272/312: https://www.ilc.cnr.it/progetti/fondamentalismi/\n",
            "Checking 273/312: https://www.ilc.cnr.it/progetti/lucet/\n",
            "Checking 274/312: https://www.ilc.cnr.it/progetti/ownw/\n",
            "Checking 275/312: https://www.ilc.cnr.it/progetti/ekeel/\n",
            "Checking 276/312: https://www.ilc.cnr.it/progetti/cip-corpus-of-italian-language-for-preschoolers/\n",
            "Checking 277/312: https://www.ilc.cnr.it/progetti/readground/\n",
            "Checking 278/312: https://www.ilc.cnr.it/progetti/testo/\n",
            "Checking 279/312: https://www.ilc.cnr.it/progetti/graspos/\n",
            "Checking 280/312: https://www.ilc.cnr.it/progetti/starwars/\n",
            "Checking 281/312: https://www.ilc.cnr.it/progetti/circe/\n",
            "Checking 282/312: https://www.ilc.cnr.it/progetti/xai-care/\n",
            "Checking 283/312: https://www.ilc.cnr.it/progetti/greekschools-2/\n",
            "Checking 284/312: https://www.ilc.cnr.it/progetti/talmud-2/\n",
            "Checking 285/312: https://www.ilc.cnr.it/progetti/lode-the-language-of-dreams/\n",
            "Checking 286/312: https://www.ilc.cnr.it/progetti/progetto-rut/\n",
            "Checking 287/312: https://www.ilc.cnr.it/progetti/cwalm/\n",
            "Checking 288/312: https://www.ilc.cnr.it/progetti/roads/\n",
            "Checking 289/312: https://www.ilc.cnr.it/progetti/vocabo/\n",
            "Checking 290/312: https://www.ilc.cnr.it/en/progetti/\n",
            "Checking 291/312: https://www.ilc.cnr.it/progetti/triplo-plus-2/\n",
            "Checking 292/312: https://www.ilc.cnr.it/progetti/gra-fo-reloaded/\n",
            "Checking 293/312: https://www.ilc.cnr.it/progetti/itant/\n",
            "Checking 294/312: https://www.ilc.cnr.it/progetti/dhelp4h/\n",
            "Checking 295/312: https://www.ilc.cnr.it/progetti/lithme-2/\n",
            "Checking 296/312: https://www.ilc.cnr.it/progetti/blue-lab-net/\n",
            "Checking 297/312: https://www.ilc.cnr.it/progetti/tailor/\n",
            "Checking 298/312: https://www.ilc.cnr.it/progetti/bestcc-study/\n",
            "Checking 299/312: https://www.ilc.cnr.it/progetti/travasi-2/\n",
            "Checking 300/312: https://www.ilc.cnr.it/progetti/diversita-religiosa/\n",
            "Checking 301/312: https://www.ilc.cnr.it/progetti/page/2/\n",
            "Checking 302/312: https://www.ilc.cnr.it/progetti/page/3/\n",
            "Checking 303/312: https://www.ilc.cnr.it/progetti/page/9/\n",
            "Checking 304/312: https://www.labcd.unipi.it/en/laboratory/\n",
            "Checking 305/312: https://www.labcd.unipi.it/en/projects/\n",
            "Checking 306/312: http://www.parthenos-project.eu\n",
            "Checking 307/312: https://www.labcd.unipi.it/en/osservatorio/dh-research-group-ict-center-fondazione-bruno-kessler/\n",
            "Checking 308/312: https://www.labcd.unipi.it/en/osservatorio/digilab-interdepartmental-center-for-research-and-services/\n",
            "Checking 309/312: https://www.labcd.unipi.it/en/osservatorio/digital-culture-laboratory/\n",
            "Checking 310/312: https://www.labcd.unipi.it/en/osservatorio/interdepartmental-research-center-in-digital-humanities/\n",
            "Checking 311/312: https://www.labcd.unipi.it/en/osservatorio/laboratory-of-perceptual-robotics-tecip-institute/\n",
            "Checking 312/312: https://www.labcd.unipi.it/en/osservatorio/laboratory-vast-lab/\n",
            "\n",
            "Summary:\n",
            "Total links checked: 312\n",
            "Active links: 299\n",
            "Failed links: 13\n",
            "\n",
            "Detailed results saved to: website_status_report.csv\n",
            "\n",
            "Sample of results:\n",
            "                                         institution  \\\n",
            "0  Digital Humanities Advanced Research Centre (D...   \n",
            "1  Digital Humanities Advanced Research Centre (D...   \n",
            "2  Digital Humanities Advanced Research Centre (D...   \n",
            "3  Digital Humanities Advanced Research Centre (D...   \n",
            "4  Digital Humanities Advanced Research Centre (D...   \n",
            "\n",
            "                                        project_name  \\\n",
            "0  /dh.arc - digital humanities advanced research...   \n",
            "1                                           research   \n",
            "2                                    research topics   \n",
            "3                                           projects   \n",
            "4                                       partnerships   \n",
            "\n",
            "                                                 url  status response  \n",
            "0                   https://centri.unibo.it/dharc/en  Active  Success  \n",
            "1          https://centri.unibo.it/dharc/en/research  Active  Success  \n",
            "2   https://centri.unibo.it/dharc/en/research/topics  Active  Success  \n",
            "3  https://centri.unibo.it/dharc/en/research/proj...  Active  Success  \n",
            "4  https://centri.unibo.it/dharc/en/research/partner  Active  Success  \n",
            "\n",
            "Status breakdown:\n",
            "status\n",
            "Active                              299\n",
            "Connection Error                      7\n",
            "Not Found                             2\n",
            "Client Error (403)                    2\n",
            "Client Error (406)                    1\n",
            "Error: Exceeded 30 redirects....      1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "def get_last_accessible_date(url):\n",
        "    \"\"\"\n",
        "    Uses the Wayback Machine CDX API to find the most recent snapshot date when the URL was accessible.\n",
        "    \"\"\"\n",
        "    if not url or pd.isna(url):  # Check for empty or NaN values\n",
        "        return None\n",
        "\n",
        "    api_url = f\"http://web.archive.org/cdx/search/cdx?url={url}&output=json&filter=statuscode:200\"\n",
        "    try:\n",
        "        response = requests.get(api_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        # Skip header and find the most recent snapshot with a 200 status code\n",
        "        if len(data) > 1:\n",
        "            last_snapshot = data[-1]  # Last entry\n",
        "            timestamp = last_snapshot[1]  # CDX API timestamp format is YYYYMMDDhhmmss\n",
        "            # Convert timestamp to a human-readable date\n",
        "            last_accessible_date = datetime.strptime(timestamp, \"%Y%m%d%H%M%S\").date()\n",
        "            return last_accessible_date\n",
        "        else:\n",
        "            return None  # No accessible snapshot found\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error checking {url}: {str(e)}\")\n",
        "        return None  # Return None instead of error message for consistency\n",
        "\n",
        "def check_non200_links_in_wayback(status_report_csv):\n",
        "    \"\"\"\n",
        "    Process only non-200 status links from the status report and check their last accessible date in Wayback Machine.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read the status report CSV file\n",
        "        df = pd.read_csv(status_report_csv)\n",
        "\n",
        "        required_columns = ['url', 'status_code']\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            raise ValueError(f\"CSV file must contain columns: {', '.join(required_columns)}\")\n",
        "\n",
        "        # Filter for non-200 status codes\n",
        "        non200_df = df[df['status_code'] != 200].copy()\n",
        "\n",
        "        if len(non200_df) == 0:\n",
        "            print(\"No non-200 status links found to process.\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Processing {len(non200_df)} non-200 status links...\")\n",
        "\n",
        "        # New column to store the last accessible date from Wayback Machine\n",
        "        non200_df['wayback_last_accessible'] = None\n",
        "\n",
        "        # Add a counter for progress tracking\n",
        "        total = len(non200_df)\n",
        "        for index, row in non200_df.iterrows():\n",
        "            if (index + 1) % 5 == 0:  # Show progress every 5 items\n",
        "                print(f\"Processing {index + 1} of {total} URLs...\")\n",
        "\n",
        "            url = row['url']\n",
        "            last_accessible_date = get_last_accessible_date(url)\n",
        "            non200_df.at[index, 'wayback_last_accessible'] = last_accessible_date\n",
        "\n",
        "            # Add a small delay to avoid overwhelming the API\n",
        "            time.sleep(1)\n",
        "\n",
        "        # Merge results back with original DataFrame\n",
        "        df = df.merge(\n",
        "            non200_df[['url', 'wayback_last_accessible']],\n",
        "            on='url',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Save results to a new CSV file\n",
        "        output_file = 'website_status_with_wayback.csv'\n",
        "        df.to_csv(output_file, index=False)\n",
        "        print(f\"\\nResults saved to {output_file}\")\n",
        "\n",
        "        # Print summary statistics\n",
        "        total_non200 = len(non200_df)\n",
        "        archived_links = non200_df['wayback_last_accessible'].notna().sum()\n",
        "        print(f\"\\nSummary:\")\n",
        "        print(f\"Total non-200 links processed: {total_non200}\")\n",
        "        print(f\"Links found in Wayback Machine: {archived_links}\")\n",
        "        print(f\"Links not found: {total_non200 - archived_links}\")\n",
        "\n",
        "        # Display results for archived links\n",
        "        if archived_links > 0:\n",
        "            print(\"\\nArchived links details:\")\n",
        "            archived_df = non200_df[non200_df['wayback_last_accessible'].notna()]\n",
        "            for _, row in archived_df.iterrows():\n",
        "                print(f\"URL: {row['url']}\")\n",
        "                print(f\"Original Status: {row['status_code']}\")\n",
        "                print(f\"Last Accessible: {row['wayback_last_accessible']}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing CSV: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Usage example\n",
        "    results = check_non200_links_in_wayback('website_status_report.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UONji9rYMaYL",
        "outputId": "dea94c16-7c2d-40fe-b77d-6710e492b390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 13 non-200 status links...\n",
            "Error checking http://artchives.fondazionezeri.unibo.it/: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Processing 15 of 13 URLs...\n",
            "Error checking https://www.iks-project.eu/: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Processing 20 of 13 URLs...\n",
            "Error checking http://projects.dharc.unibo.it/mauth/search: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Error checking http://it/264/laboratorio-di-epigrafia-greca: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Error checking http://vbd.humnet.unipi.it/beta2/: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Error checking https://italianacademy.columbia.edu/content/frida: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Error checking https://web.unica.it/unica/it/utility_ricerca.page: HTTPConnectionPool(host='web.archive.org', port=80): Read timed out. (read timeout=10)\n",
            "Processing 235 of 13 URLs...\n",
            "Error checking https://www.comicon.it/class/alla-ricerca-dellunderground-riviste-stampa-alternativa-generazioni/: HTTPConnectionPool(host='web.archive.org', port=80): Max retries exceeded with url: /cdx/search/cdx?url=https://www.comicon.it/class/alla-ricerca-dellunderground-riviste-stampa-alternativa-generazioni/&output=json&filter=statuscode:200 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7d73430ce1a0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "Results saved to website_status_with_wayback.csv\n",
            "\n",
            "Summary:\n",
            "Total non-200 links processed: 13\n",
            "Links found in Wayback Machine: 5\n",
            "Links not found: 8\n",
            "\n",
            "Archived links details:\n",
            "URL: http://www.iccd.beniculturali.it/it/progetti/4597/arco-architettura-della-conoscenza-ontologie-per-la-descrizione-del-patrimonio-culturale\n",
            "Original Status: nan\n",
            "Last Accessible: 2024-06-24\n",
            "--------------------------------------------------\n",
            "URL: http://vcg.isti.cnr.it/cross/\n",
            "Original Status: 404.0\n",
            "Last Accessible: 2023-11-29\n",
            "--------------------------------------------------\n",
            "URL: https://sourceforge.net/projects/evt-project/\n",
            "Original Status: 403.0\n",
            "Last Accessible: 2023-10-06\n",
            "--------------------------------------------------\n",
            "URL: http://evt.labcd.unipi.it/\n",
            "Original Status: nan\n",
            "Last Accessible: 2024-09-10\n",
            "--------------------------------------------------\n",
            "URL: http://www.getty.edu/research/\n",
            "Original Status: nan\n",
            "Last Accessible: 2024-10-08\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}